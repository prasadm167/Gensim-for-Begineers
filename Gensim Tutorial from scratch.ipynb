{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"Wikipedia's collection of category pages is a classified index system\",\n",
    "             \"It is automatically generated from category tags at the bottoms of articles and most other pages\",\n",
    "             \"Nearly all of the articles available so far on the website can be found through these subject indexes\"]\n",
    "\n",
    "documents_2 = [\"Wikipedia is a compendium of the world's knowledge.\",\n",
    "               \" If you know what you are looking for, type it into Wikipedia's search box.\",\n",
    "               \" If, however, you need a bird's eye view of what Wikipedia has to offer.\",\n",
    "               \" see its main contents pages below, which in turn list more specific pages.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [[i for i in doc.split()] for doc in documents_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = corpora.Dictionary(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(43 unique tokens: ['Wikipedia', 'a', 'compendium', 'is', 'knowledge.']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Wikipedia': 0, 'a': 1, 'compendium': 2, 'is': 3, 'knowledge.': 4, 'of': 5, 'the': 6, \"world's\": 7, 'If': 8, \"Wikipedia's\": 9, 'are': 10, 'box.': 11, 'for,': 12, 'into': 13, 'it': 14, 'know': 15, 'looking': 16, 'search': 17, 'type': 18, 'what': 19, 'you': 20, 'If,': 21, \"bird's\": 22, 'eye': 23, 'has': 24, 'however,': 25, 'need': 26, 'offer.': 27, 'to': 28, 'view': 29, 'below,': 30, 'contents': 31, 'in': 32, 'its': 33, 'list': 34, 'main': 35, 'more': 36, 'pages': 37, 'pages.': 38, 'see': 39, 'specific': 40, 'turn': 41, 'which': 42}\n"
     ]
    }
   ],
   "source": [
    "print(dct.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = [[text for text in doc.split()] for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dct2 = corpora.Dictionary(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct2 = corpora.Dictionary(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(36 unique tokens: [\"Wikipedia's\", 'a', 'category', 'classified', 'collection']...)\n"
     ]
    }
   ],
   "source": [
    "print(dct2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Wikipedia's\": 0, 'a': 1, 'category': 2, 'classified': 3, 'collection': 4, 'index': 5, 'is': 6, 'of': 7, 'pages': 8, 'system': 9, 'It': 10, 'and': 11, 'articles': 12, 'at': 13, 'automatically': 14, 'bottoms': 15, 'from': 16, 'generated': 17, 'most': 18, 'other': 19, 'tags': 20, 'the': 21, 'Nearly': 22, 'all': 23, 'available': 24, 'be': 25, 'can': 26, 'far': 27, 'found': 28, 'indexes': 29, 'on': 30, 'so': 31, 'subject': 32, 'these': 33, 'through': 34, 'website': 35}\n"
     ]
    }
   ],
   "source": [
    "print(dct2.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [simple_preprocess(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 0, 'classified': 1, 'collection': 2, 'index': 3, 'is': 4, 'of': 5, 'pages': 6, 'system': 7, 'wikipedia': 8, 'and': 9, 'articles': 10, 'at': 11, 'automatically': 12, 'bottoms': 13, 'from': 14, 'generated': 15, 'it': 16, 'most': 17, 'other': 18, 'tags': 19, 'the': 20, 'all': 21, 'available': 22, 'be': 23, 'can': 24, 'far': 25, 'found': 26, 'indexes': 27, 'nearly': 28, 'on': 29, 'so': 30, 'subject': 31, 'these': 32, 'through': 33, 'website': 34}\n"
     ]
    }
   ],
   "source": [
    "dct3 = corpora.Dictionary(token_list)\n",
    "print(dct3.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1)],\n",
      " [(6, 1),\n",
      "  (8, 1),\n",
      "  (9, 1),\n",
      "  (10, 1),\n",
      "  (11, 1),\n",
      "  (12, 1),\n",
      "  (13, 1),\n",
      "  (14, 1),\n",
      "  (15, 1),\n",
      "  (16, 1)],\n",
      " [(5, 2),\n",
      "  (16, 1),\n",
      "  (17, 1),\n",
      "  (18, 1),\n",
      "  (19, 1),\n",
      "  (20, 1),\n",
      "  (21, 1),\n",
      "  (22, 1),\n",
      "  (23, 1)],\n",
      " [(21, 2), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]]\n"
     ]
    }
   ],
   "source": [
    "my_dict = corpora.Dictionary()\n",
    "my_corpus = [my_dict.doc2bow(doc,allow_update=True) for doc in token_list]\n",
    "pprint(my_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = [[(my_dict[id], count) for id, count in line] for line in my_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('acknowledge', 1),\n",
      "  ('are', 1),\n",
      "  ('preparing', 1),\n",
      "  ('report', 1),\n",
      "  ('saudis', 1),\n",
      "  ('that', 2),\n",
      "  ('the', 1),\n",
      "  ('will', 1)],\n",
      " [('the', 1),\n",
      "  ('an', 1),\n",
      "  ('death', 1),\n",
      "  ('jamal', 1),\n",
      "  ('journalist', 1),\n",
      "  ('khashoggi', 1),\n",
      "  ('of', 1),\n",
      "  ('result', 1),\n",
      "  ('saudi', 1),\n",
      "  ('was', 1)],\n",
      " [('that', 2),\n",
      "  ('was', 1),\n",
      "  ('intended', 1),\n",
      "  ('interrogation', 1),\n",
      "  ('lead', 1),\n",
      "  ('one', 1),\n",
      "  ('to', 1),\n",
      "  ('went', 1),\n",
      "  ('wrong', 1)],\n",
      " [('to', 2),\n",
      "  ('abduction', 1),\n",
      "  ('according', 1),\n",
      "  ('from', 1),\n",
      "  ('his', 1),\n",
      "  ('sources', 1),\n",
      "  ('turkey', 1),\n",
      "  ('two', 1)]]\n"
     ]
    }
   ],
   "source": [
    "pprint(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
